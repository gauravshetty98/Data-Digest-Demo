{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from SlackChannelReader import SlackChannelReader\n",
    "from ComponentMatcher import ComponentMatcher\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded variables\n"
     ]
    }
   ],
   "source": [
    "#Initializing:\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Get credentials from environment\n",
    "slack_token = os.getenv(\"SLACK_TOKEN\")\n",
    "channel_id = os.getenv(\"CHANNEL_ID\")\n",
    "csv_path =  os.getenv(\"BOM_V16_CSV_PATH\")\n",
    "\n",
    "print(\"loaded variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 1] Extracting Slack messages...\n",
      "\n",
      "‚úÖ Extracted 10 messages\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract messages from Slack\n",
    "print(\"\\n[STEP 1] Extracting Slack messages...\")\n",
    "try:\n",
    "    slack_reader = SlackChannelReader(token=slack_token, default_channel_id=channel_id)\n",
    "    messages = slack_reader.extract_messages(lookback_minutes=120, print_output=False)\n",
    "    \n",
    "    if not messages:\n",
    "        print(\"\\n‚ùå No messages extracted. Exiting.\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Extracted {len(messages)} messages\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error extracting Slack messages: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 2] Preparing texts for component matching...\n",
      "Loading NLP model...\n",
      "Loading data from /Users/gauravshetty/Documents/othjer projects/EverCurrent - Demo/Machine_data/FarmBot Genesis v1.7 full/BOM/structuredBOM of FarmBot Genesis v1.7.csv...\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[STEP 2] Preparing texts for component matching...\")\n",
    "message_texts = [msg[\"text\"] for msg in messages if msg[\"text\"]]\n",
    "\n",
    "try:\n",
    "    matcher = ComponentMatcher(file_path=csv_path)\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error loading Component Matcher: {e}\")\n",
    "    print(f\"Make sure '{csv_path}' exists or set COMPONENT_CSV_PATH in .env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 4] Finding components in messages...\n",
      "\n",
      "‚úÖ Found child: 115 component matches!\n",
      "\n",
      "\n",
      "‚úÖ Found full: 99 component matches!\n",
      "\n",
      "\n",
      "üìÅ Results saved to: matched_components.csv\n",
      "FLOW TEST COMPLETE\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[STEP 4] Finding components in messages...\")\n",
    "child_only_df = matcher.find_components(message_texts)\n",
    "results_df = matcher.parent_extractor(child_only_df)\n",
    "\n",
    "if results_df.empty:\n",
    "    print(\"\\n‚ùå No components found in the messages.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Found child: {len(child_only_df)} component matches!\\n\")\n",
    "    print(f\"\\n‚úÖ Found full: {len(results_df)} component matches!\\n\")\n",
    "    #print(results_df.to_string())\n",
    "    \n",
    "    # Save to CSV for review\n",
    "    output_file = \"matched_components.csv\"\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nüìÅ Results saved to: {output_file}\")\n",
    "\n",
    "print(\"FLOW TEST COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OpenRouterClient import OpenRouterClient\n",
    "from PromptDigest import get_manufacturing_digest_prompt\n",
    "from PromptDigest import parse_llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = get_manufacturing_digest_prompt(messages, results_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "or_api_key = os.getenv(\"OPEN_ROUTER_API_KEY\")\n",
    "orclient = OpenRouterClient(or_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = orclient.send_message(prompt)\n",
    "llm_output = orclient.get_response_text(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = parse_llm_output(llm_output)\n",
    "discussions = pd.DataFrame(parsed_data)\n",
    "discussions.to_csv('discussions.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"matched_components.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======\n",
    "Checking DB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of    Component ID                                            Summary  \\\n",
      "0  3.2.5.11.1.3  The Push Button Nut in the Electronic Box has ...   \n",
      "1     3.2.2.3.3  The M5 Eccentric Spacer on the Gantry Wheel Pl...   \n",
      "\n",
      "                                       Latest Update  \n",
      "0  Ordering samples in three durometers for testi...  \n",
      "1  Proposal to increase offset from 0.5mm to 0.75...  >\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "db_url = os.getenv(\"DATABASE_URL\")\n",
    "df = pd.read_csv(\"discussions.csv\")\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://fastapi_user:8080@localhost:5432/discussions_db\n"
     ]
    }
   ],
   "source": [
    "print(db_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine(db_url)\n",
    "df.to_sql(name='discussion_summaries',\n",
    "                    con=engine,\n",
    "                    if_exists='append',\n",
    "                    index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
